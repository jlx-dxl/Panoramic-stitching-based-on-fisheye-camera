{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "770a9536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import biaoding1\n",
    "import numpy as np\n",
    "from Stitcher import Stitcher\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129655cb",
   "metadata": {},
   "source": [
    "### 获取H矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1542aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n= 1\n",
      "n= 2\n",
      "n= 3\n",
      "n= 4\n",
      "n= 5\n",
      "n= 6\n",
      "n= 7\n",
      "n= 8\n",
      "n= 9\n",
      "n= 10\n",
      "strat video\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_17280/1465733009.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"strat video\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult_right\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvis_right\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstitcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstitch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshowMatches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;31m# (result_left, vis_left) = stitcher.stitchright([frame[1], frame[2]], showMatches=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mresult_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_right\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\大四上\\传感器\\全景拼接\\Stitcher.py\u001b[0m in \u001b[0;36mstitch\u001b[1;34m(self, images, ratio, reprojThresh, showMatches)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# 匹配两张图片的所有特征点，返回匹配结果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatchKeypoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkpsA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkpsB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeaturesA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeaturesB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreprojThresh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# 如果返回结果为空，没有匹配成功的特征点，退出算法\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\大四上\\传感器\\全景拼接\\Stitcher.py\u001b[0m in \u001b[0;36mmatchKeypoints\u001b[1;34m(self, kpsA, kpsB, featuresA, featuresB, ratio, reprojThresh)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;31m# 计算视角变换矩阵\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindHomography\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mptsA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mptsB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRANSAC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreprojThresh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;31m# 返回结果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "s=[]\n",
    "s.append(None)\n",
    "number_of_camera=3\n",
    "for index in range(1,number_of_camera+1):\n",
    "    s.append(cv2.VideoCapture(index))\n",
    "    s[index].set(3,1920)\n",
    "    s[index].set(4,1080)\n",
    "\n",
    "R=np.load(r\"D:/大四上/传感器/全景拼接/data/R.npy\")\n",
    "left=np.load(r\"D:/大四上/传感器/全景拼接/data/left.npy\")\n",
    "right=np.load(r\"D:/大四上/传感器/全景拼接/data/right.npy\")\n",
    "top=np.load(r\"D:/大四上/传感器/全景拼接/data/top.npy\")\n",
    "bottom=np.load(r\"D:/大四上/传感器/全景拼接/data/bottom.npy\")\n",
    "mapx = np.load(r\"D:/大四上/传感器/全景拼接/data/mapx.npy\",allow_pickle=True)\n",
    "mapy = np.load(r\"D:/大四上/传感器/全景拼接/data/mapy.npy\",allow_pickle=True)\n",
    "\n",
    "stitcher=Stitcher()\n",
    "frame=[None,None,None,None]\n",
    "n=0\n",
    "w_1_3=900\n",
    "w_2=840\n",
    "h_1_2_3=900\n",
    "\n",
    "while True:\n",
    "    n += 1\n",
    "    if n <= 10:\n",
    "      print(\"n=\",n)\n",
    "    for index in range(1,number_of_camera+1):\n",
    "\n",
    "        ret1,frame[index]=s[index].read()\n",
    "        frame[index]=frame[index][top[index]:bottom[index], left[index]:right[index]]\n",
    "        frame[index] = cv2.remap(frame[index], mapx[index], mapy[index], interpolation=cv2.INTER_LINEAR,borderMode=cv2.BORDER_CONSTANT)\n",
    "\n",
    "    frame[1]=frame[1][int(0.5*(frame[1].shape[0]-h_1_2_3)):int(0.5*(frame[1].shape[0]+h_1_2_3)),0:w_1_3]\n",
    "    frame[2]=frame[2][int(0.5*(frame[1].shape[0]-h_1_2_3)):int(0.5*(frame[1].shape[0]+h_1_2_3)),int(0.5*(frame[2].shape[0]-w_2)):int(0.5*(frame[2].shape[0]+w_2))]\n",
    "    frame[3]=frame[3][int(0.5*(frame[1].shape[0]-h_1_2_3)):int(0.5*(frame[1].shape[0]+h_1_2_3)),frame[3].shape[1]-w_1_3:frame[3].shape[1]]\n",
    "\n",
    "    if n>=10:\n",
    "        if n==10:\n",
    "            print(\"strat video\")\n",
    "        (result_right,H, vis_right) = stitcher.stitch([frame[1], frame[3]], showMatches=True)\n",
    "        # (result_left, vis_left) = stitcher.stitchright([frame[1], frame[2]], showMatches=True)\n",
    "        result_right = cv2.resize(result_right, None, fx=0.5, fy=0.5)\n",
    "        # result_left = cv2.resize(result_left, None, fx=0.5, fy=0.5)\n",
    "\n",
    "#         for index in range(1, number_of_camera+1):\n",
    "#             # frame[index] = cv2.resize(frame[index], (0, 0), fx=0.5, fy=0.5)\n",
    "#             if n == 10:\n",
    "#                 print(\"the highth of camera\" + str(index) + \" is:\", frame[index].shape[0],\n",
    "#                       \"the width of camera\" + str(index) + \" is:\", frame[index].shape[1])\n",
    "#             cv2.imshow(\"camera\"+str(index),frame[index])\n",
    "\n",
    "        cv2.imshow(\"result_right\", result_right)\n",
    "        # cv2.imshow(\"result_left\", result_left)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xff == (ord('q')):\n",
    "        break\n",
    "\n",
    "for index in range(1,number_of_camera+1):\n",
    "    s[index].release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b43594b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
